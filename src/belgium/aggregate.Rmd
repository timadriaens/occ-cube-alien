---
title: "Aggregate occurrence data"
author:
- Damiano Oldoni
- Peter Desmet
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

In this document we aggregate data. The goal is to produce two *data cubes*, one at kingdom level (baseline for future corrections of research effort bias) and one at species level for taxa in the unfied checklist.

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r load_libraries}
library(tidyverse)      # To do datascience
library(sp)             # To work with geospatial data
library(here)           # To find files
library(rgbif)          # To use GBIF services
library(glue)           # To write queries
library(RSQLite)        # To interact with SQlite databases
```

Name and path of `.sqlite` file:

```{r name_path}
key <- "0044021-181108115102211"
sqlite_file <- paste(key, "occurrence.sqlite", sep = "_")
sqlite_path <- here("data", "interim", sqlite_file)
```

Table name:

```{r define_table_name}
table_name <- "occ_be"
```

Open connection to database:

```{r open_connection_to_db}
sqlite_occ <- dbConnect(SQLite(), dbname = sqlite_path)
```

# Aggregate at kingdom level - baseline

In this section we will calculate how many occurrences have been recorded for each year, EEA cell code and kingdom. For speeding up the search in database, we create an index on these rows if not present:

```{r create_idx_kingdom}
idx_baseline <- "idx_year_cell_kingdom"
# get indexes on table
query <- glue_sql(
    "PRAGMA index_list({table_name})",
    table_name = table_name,
    .con = sqlite_occ
)
indexes_all <- dbGetQuery(sqlite_occ, query)

# create index if not present
if (!idx_baseline %in% indexes_all$name) {
  query <- glue_sql(
  "CREATE INDEX {`idx`} ON {table_name} ({`cols_idx`*})",
  idx = idx_baseline,
  table_name = table_name,
  cols_idx = c("year", "eea_cell_code", "kingdomKey"),
  .con = sqlite_occ
  )
  dbExecute(sqlite_occ, query)
}
```

Group by  `year`, `eea_cell_code` and `kingdomKey` and count number of occurrences for each group:

```{r get_datacube_kingdom}
query <- glue_sql(
  "SELECT {`cols`*}, COUNT(_ROWID_) FROM {table} GROUP BY {`cols`*}",
  cols = c("year", "eea_cell_code", "kingdomKey"),
  table = table_name,
  .con = sqlite_occ
)
occ_cube_baseline <- 
  dbGetQuery(sqlite_occ, query) %>%
  rename(n = "COUNT(_ROWID_)")
```

Preview:

```{r preview_occ_cube_baseline}
occ_cube_baseline %>% 
  head()
```

The kingdom names can be retrieved easily by GBIF:

```{r get_kingdom}
kingdom_df <- tibble(
  kingdomKey = unique(occ_cube_baseline$kingdomKey))
kingdom_df <- 
  kingdom_df %>%
  mutate(kingdom = map_chr(
    kingdomKey, 
    function(x) {
      name_usage(x, return = "data") %>%
        pull(scientificName)
      })
  )
kingdom_df
```

Save as text file:

```{r save_baseline_datacube}
write_tsv(occ_cube_baseline,
          here("data", "processed", "cube_belgium_baseline.tsv"),
          na = "")
```

Close connection:

```{r close_connection}
dbDisconnect(sqlite_occ)
```
